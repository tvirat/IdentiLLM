{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecc7c9b4",
      "metadata": {
        "id": "ecc7c9b4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import re\n",
        "from sklearn.model_selection import GroupShuffleSplit, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5592ee7",
      "metadata": {
        "id": "b5592ee7"
      },
      "outputs": [],
      "source": [
        "INPUT = \"training_data_clean.csv\"\n",
        "\n",
        "ID_COL  = \"student_id\"\n",
        "TARGET  = \"label\"\n",
        "\n",
        "TEXT_COLS = [\n",
        "    \"In your own words, what kinds of tasks would you use this model for?\",\n",
        "    \"Which types of tasks do you feel this model handles best? (Select all that apply.)\",\n",
        "    \"For which types of tasks do you feel this model tends to give suboptimal responses? (Select all that apply.)\",\n",
        "    \"Think of one task where this model gave you a suboptimal response. What did the response look like, and why did you find it suboptimal?\",\n",
        "    \"When you verify a response from this model, how do you usually go about it?\"\n",
        "]\n",
        "\n",
        "LIKERT_COLS = [\n",
        "    \"How likely are you to use this model for academic tasks?\",\n",
        "    \"Based on your experience, how often has this model given you a response that felt suboptimal?\",\n",
        "    \"How often do you expect this model to provide responses with references or supporting evidence?\",\n",
        "    \"How often do you verify this model's responses?\"\n",
        "]\n",
        "\n",
        "MODIFIED_TEXT_FEATS = [\n",
        "    \"Writing or debugging code\",\n",
        "    \"Math computations\",\n",
        "    \"Explaining complex concepts simply\",\n",
        "    \"Drafting professional text (e.g., emails, résumés)\",\n",
        "    \"Data processing or analysis\",\n",
        "    \"Brainstorming or generating creative ideas\",\n",
        "    \"Writing or editing essays/reports\",\n",
        "    \"Converting content between formats (e.g., LaTeX)\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59340a58",
      "metadata": {
        "id": "59340a58"
      },
      "outputs": [],
      "source": [
        "def reformat_rename(df):\n",
        "  # Rename columns\n",
        "  new_names = [\"student_id\", \"tasks_open\", \"academic_scale\", \"task_types\",\n",
        "          \"suboptimal_scale\",\"suboptimal_types\",\n",
        "          \"suboptimal_open\", \"ref_scale\", \"verify_scale\",\"verify_open\",\"label\"]\n",
        "  df.columns = new_names\n",
        "\n",
        "  # Remove parantheses in multiple select options. This is to prepare for the next splitting step\n",
        "  df['task_types'] = df['task_types'].str.replace(r'\\([^)]*\\)', '', regex=True)\n",
        "  df['suboptimal_types'] = df['suboptimal_types'].str.replace(r'\\([^)]*\\)', '', regex=True)\n",
        "\n",
        "  for feat in MODIFIED_TEXT_FEATS:\n",
        "    # Create a one-hot flag per row: whether the multi-select text contains the option\n",
        "    # Use string containment on the column (handle NaN -> empty string) and cast to int\n",
        "    df[f'{feat}1'] = df['task_types'].fillna('').astype(str).str.contains(feat, regex=False, na=False).astype(int)\n",
        "    df[f'{feat}2'] = df['suboptimal_types'].fillna('').astype(str).str.contains(feat, regex=False, na=False).astype(int)\n",
        "\n",
        "  df = df.drop(columns=['task_types', 'suboptimal_types'])\n",
        "\n",
        "  df = df.convert_dtypes()\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a244a40",
      "metadata": {
        "id": "0a244a40"
      },
      "outputs": [],
      "source": [
        "def clean_data(df):\n",
        "  # Normalize missing tokens\n",
        "  # Convert non-breaking spaces to normal spaces, blank-only cells → NaN\n",
        "  df.replace({u\"\\u00A0\": \" \"}, regex=True, inplace=True)\n",
        "  df.replace(r\"^\\s*$\", np.nan, regex=True, inplace=True)\n",
        "\n",
        "  # Convert Likert scales to just numbers\n",
        "  LIKERT_REGEX = re.compile(r\"^\\s*(\\d+)\\s*—?.*$\")\n",
        "\n",
        "  for c in LIKERT_COLS:\n",
        "      if c in df.columns:\n",
        "          # extract the number; invalid/missing stay NaN\n",
        "          df[c] = df[c].astype(str).str.extract(LIKERT_REGEX)[0].astype(float)\n",
        "\n",
        "  # Replace missing Likert values with column median\n",
        "  medians = df[LIKERT_COLS].median(numeric_only=True)\n",
        "  df[LIKERT_COLS] = df[LIKERT_COLS].fillna(medians)\n",
        "\n",
        "  # Fill missing text with \"no_response\"\n",
        "  for c in TEXT_COLS:\n",
        "      if c in df.columns:\n",
        "          df[c] = df[c].fillna(\"no_response\")\n",
        "\n",
        "  df = reformat_rename(df)\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8959fbf",
      "metadata": {
        "id": "d8959fbf"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(INPUT, keep_default_na=True, skipinitialspace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "344f8a49",
      "metadata": {
        "id": "344f8a49"
      },
      "outputs": [],
      "source": [
        "df = clean_data(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15a45a64",
      "metadata": {
        "id": "15a45a64"
      },
      "outputs": [],
      "source": [
        "# Count the number of null values in each feature column\n",
        "# df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "089fa8df",
      "metadata": {
        "id": "089fa8df"
      },
      "outputs": [],
      "source": [
        "def split_dataset(df):\n",
        "  # split (70:15:15) while keeping student_id groups intact\n",
        "  gss = GroupShuffleSplit(n_splits=1, test_size=0.15, random_state=311)\n",
        "  train_val_idx, test_idx = next(gss.split(df, groups=df[ID_COL]))\n",
        "  train_val_df = df.iloc[train_val_idx].reset_index(drop=True)\n",
        "  test_df = df.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "  # then split train_val into train/val by groups\n",
        "  val_ratio_within_trainval = 0.15 / 0.85\n",
        "  gss2 = GroupShuffleSplit(n_splits=1, test_size=val_ratio_within_trainval, random_state=311)\n",
        "  train_idx, val_idx = next(gss2.split(train_val_df, groups=train_val_df[ID_COL]))\n",
        "  train_df = train_val_df.iloc[train_idx].reset_index(drop=True)\n",
        "  val_df = train_val_df.iloc[val_idx].reset_index(drop=True)\n",
        "\n",
        "  return train_df, val_df, test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "430b87b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "430b87b0",
        "outputId": "f1d461f4-44f5-4115-949e-bc69dec89562"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 573\n",
            "valid:   126\n",
            "test:  126\n"
          ]
        }
      ],
      "source": [
        "train_df, valid_df, test_df = split_dataset(df)\n",
        "print(\"train:\", len(train_df))\n",
        "print(\"valid:  \", len(valid_df))\n",
        "print(\"test: \", len(test_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "340b4341",
      "metadata": {
        "id": "340b4341"
      },
      "outputs": [],
      "source": [
        "def get_train_data(df, t_train_onehot: bool):\n",
        "\n",
        "    if t_train_onehot:\n",
        "        t_train = pd.get_dummies(df['label'])\n",
        "    else:\n",
        "        t_train = df['label']\n",
        "    x_train = df.drop(columns=['label', 'student_id'])\n",
        "\n",
        "    return x_train, t_train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "stops = ENGLISH_STOP_WORDS\n",
        "stops = list(stops)\n"
      ],
      "metadata": {
        "id": "YErTHmtzM1NL"
      },
      "id": "YErTHmtzM1NL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "stops = nlp.Defaults.stop_words\n"
      ],
      "metadata": {
        "id": "wzZPG2KmNVKs"
      },
      "id": "wzZPG2KmNVKs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stops = list(stops)"
      ],
      "metadata": {
        "id": "_SvIg8wkNY4S"
      },
      "id": "_SvIg8wkNY4S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter, defaultdict\n",
        "word_doc_count = defaultdict(int)"
      ],
      "metadata": {
        "id": "xbjRyZfzSYK5"
      },
      "id": "xbjRyZfzSYK5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dae025b",
      "metadata": {
        "id": "9dae025b"
      },
      "outputs": [],
      "source": [
        "def create_vocab(df: pd.DataFrame, features: list[str]):\n",
        "    \"\"\"\n",
        "    Returns a list of vocab words.\n",
        "    Parameters:\n",
        "    - df: cleaned dataset\n",
        "    - col: list of open-ended features\n",
        "    \"\"\"\n",
        "    min_df = 5\n",
        "    vocab = set()\n",
        "\n",
        "    skip_list = ['THIS', 'MODEL', '', '-', ' ', 'in', 'and', 'the', 'on', 'at',\n",
        "                 'of', 'suboptimal', 'verify', 'open', 'types', 'ref', 'student',\n",
        "                 'id'\n",
        "                 ] + stops\n",
        "\n",
        "    # words/symbols to avoid adding to vocab\n",
        "    skip_words = {word.lower() for word in skip_list if word.strip()}\n",
        "\n",
        "    # For each open ended feature, split the string into words and add to vocab\n",
        "    for feat in features:\n",
        "        df[feat].apply(lambda line: add_to_vocab(line, skip_words))\n",
        "\n",
        "    vocab = {word for word, count in word_doc_count.items() if count >= min_df}\n",
        "\n",
        "    return list(vocab)\n",
        "\n",
        "\n",
        "def add_to_vocab(line: str, skip_words: set):\n",
        "    \"\"\"\n",
        "    Helper function to split a given line and add to vocab\n",
        "    \"\"\"\n",
        "    line = line.lower().strip()\n",
        "    words = re.split(r'[ ,.?:[[\\\\\\]/{()}///\"\";]+', line)\n",
        "    for word in words:\n",
        "          if word in skip_words or word.isdigit():\n",
        "            continue\n",
        "          word_doc_count[word] += 1\n",
        "\n",
        "\n",
        "def create_bow(df, vocab, features):\n",
        "    \"\"\"\n",
        "    Returns the df with bow for the given list of features and vocab.\n",
        "    - df: the DataFrame to add bow to\n",
        "    - vocab: list of unique words\n",
        "    - features: list of open ended features to turn into bow\n",
        "    \"\"\"\n",
        "    df_copy = df.copy()\n",
        "\n",
        "    # Initialize a new DataFrame for Bag-of-Words features with zeros\n",
        "    bow_data = np.zeros((df_copy.shape[0], len(vocab)), dtype=int)\n",
        "    bow_df = pd.DataFrame(bow_data, columns=vocab, index=df_copy.index)\n",
        "\n",
        "    # Populate the BoW DataFrame using vectorized operations\n",
        "    for feat in features:\n",
        "        # Ensure the feature column is string type and handle NaN values\n",
        "        text_series = df_copy[feat].fillna('').astype(str).str.lower()\n",
        "        for word in vocab:\n",
        "            # Use .str.contains to check for whole words, update the bow_df\n",
        "            # Use bitwise OR to combine results across multiple text features\n",
        "            bow_df[word] = bow_df[word] | text_series.str.contains(r'\\b' + re.escape(word) + r'\\b', regex=True).astype(int)\n",
        "\n",
        "    # Drop the original open-ended text columns from the df_copy\n",
        "    df_copy = df_copy.drop(columns=features)\n",
        "\n",
        "    # Concatenate the original df_copy (without text columns) with the new bow_df\n",
        "    final_df = pd.concat([df_copy, bow_df], axis=1)\n",
        "\n",
        "    # Assert the correct number of columns\n",
        "    expected_cols = df.shape[1] - len(features) + len(vocab)\n",
        "    assert(final_df.shape[1] == expected_cols)\n",
        "\n",
        "    return final_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ea37802",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ea37802",
        "outputId": "55a23e1c-2e78-4209-80a7-10506dd976c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of vocab: 704\n"
          ]
        }
      ],
      "source": [
        "open_features = ['tasks_open', 'suboptimal_open', 'verify_open']\n",
        "vocab = create_vocab(train_df, open_features)\n",
        "print(\"Length of vocab:\", len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "id": "DsmkxJVLbwjj"
      },
      "id": "DsmkxJVLbwjj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11a36954",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11a36954",
        "outputId": "a973e0ef-359b-456c-e612-6c73c3f022bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bow_df shape:  (573, 726)\n"
          ]
        }
      ],
      "source": [
        "train_bow_df = create_bow(train_df, vocab, open_features)\n",
        "print(\"bow_df shape: \", train_bow_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_bow_df = create_bow(valid_df, vocab, open_features)\n",
        "print(\"bow_df shape for valid df: \", valid_bow_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWgQxeiNJhY9",
        "outputId": "516abcc3-3808-41a5-f245-f92c5901fce7"
      },
      "id": "KWgQxeiNJhY9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bow_df shape for valid df:  (126, 726)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_bow_df = create_bow(test_df, vocab, open_features)\n",
        "print(\"bow_df shape for test df: \", test_bow_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMjl6TEQJwTH",
        "outputId": "d76e0c84-9117-496a-c5c6-8fe1004f870d"
      },
      "id": "ZMjl6TEQJwTH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bow_df shape for test df:  (126, 726)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bee0d33e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bee0d33e",
        "outputId": "d2749882-8d16-4473-a82b-01b588dc946f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape:  (573, 724)\n",
            "t_train shape:  (573,)\n"
          ]
        }
      ],
      "source": [
        "x_train, t_train = get_train_data(train_bow_df, False)\n",
        "print(\"x_train shape: \", x_train.shape)\n",
        "print(\"t_train shape: \", t_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_valid, t_valid = get_train_data(valid_bow_df, False)\n",
        "x_test, t_test = get_train_data(test_bow_df, False)"
      ],
      "metadata": {
        "id": "Vk13v54_J3gZ"
      },
      "id": "Vk13v54_J3gZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RFC with default hyperparams on x_train, t_train\n",
        "rfc = RandomForestClassifier(random_state=311)\n",
        "rfc = rfc.fit(X=x_train, y=t_train)\n",
        "# Check accuracy on x_valid, t_valid\n",
        "rfc_accuracy = rfc.score(X=x_valid, y=t_valid)\n",
        "print(\"Valid accuracy for the base RFC: \", rfc_accuracy)\n",
        "print(\"Train accuracy for the base RFC: \", rfc.score(X=x_train, y=t_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdOC2ytpKBjw",
        "outputId": "b269bebe-771f-41f8-b7a1-a827fc40ee5f"
      },
      "id": "bdOC2ytpKBjw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid accuracy for the base RFC:  0.6984126984126984\n",
            "Train accuracy for the base RFC:  0.9947643979057592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tune hyperparams using RandomSearchCV\n",
        "param_dist = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'n_estimators': [50, 100, 200, 300],\n",
        "    'max_depth': [None, 5, 8, 10, 13, 15, 20, 25, 30],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'min_samples_split': [25, 30, 35, 40, 45],\n",
        "    'min_samples_leaf': [10, 15, 20, 25, 30, 35, 40]\n",
        "}"
      ],
      "metadata": {
        "id": "ljHplfTvKLFu"
      },
      "id": "ljHplfTvKLFu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = RandomizedSearchCV(\n",
        "    estimator=rfc,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=300,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    random_state=311\n",
        ")\n",
        "search = search.fit(x_train, t_train)"
      ],
      "metadata": {
        "id": "8L_ggw_wKL-o"
      },
      "id": "8L_ggw_wKL-o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search.best_params_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAnRHEKFOtaP",
        "outputId": "4669e231-5f65-45ac-91b4-511f0a4cfd99"
      },
      "id": "mAnRHEKFOtaP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': 50,\n",
              " 'min_samples_split': 40,\n",
              " 'min_samples_leaf': 10,\n",
              " 'max_features': 'sqrt',\n",
              " 'max_depth': 8,\n",
              " 'criterion': 'entropy'}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RFC with custom bow with all features (same as below except hyperparams)\n",
        "rfc2 = RandomForestClassifier(\n",
        "    random_state=311,\n",
        "    criterion='entropy',\n",
        "    n_estimators=200,\n",
        "    max_depth=8,\n",
        "    # max_features=,\n",
        "    min_samples_split=40,\n",
        "    min_samples_leaf=10\n",
        "    )\n",
        "rfc2 = rfc2.fit(X=x_train, y=t_train)\n",
        "# Check accuracy on x_valid, t_valid\n",
        "rfc_accuracy = rfc2.score(X=x_valid, y=t_valid)\n",
        "print(\"Valid accuracy for the base RFC: \", rfc_accuracy)\n",
        "print(\"Train accuracy for the base RFC: \", rfc2.score(X=x_train, y=t_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ponLhWAJOx9A",
        "outputId": "5a2937eb-3d06-4161-c3fe-57ec66bdba36"
      },
      "id": "ponLhWAJOx9A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid accuracy for the base RFC:  0.7063492063492064\n",
            "Train accuracy for the base RFC:  0.7382198952879581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rfc2.score(X=x_test, y=t_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvLBPSzFeUKY",
        "outputId": "a268460c-1253-4cd1-d729-2c154e5c9623"
      },
      "id": "yvLBPSzFeUKY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6428571428571429"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46cd6aea",
      "metadata": {
        "id": "46cd6aea"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "jupyter",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}